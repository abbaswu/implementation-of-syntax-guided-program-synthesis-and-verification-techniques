{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb24f90-1309-47e2-a5f2-94eb336659f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "\n",
    "from verification_oracle import verification_oracle\n",
    "\n",
    "\n",
    "z3_x = Int('x')\n",
    "z3_y = Int('y')\n",
    "\n",
    "z3_input_variable_list = [z3_x, z3_y]\n",
    "z3_function_declaration = max2 = Function('max2', IntSort(), IntSort(), IntSort())\n",
    "z3_constraint = And(max2(z3_x, z3_y) >= z3_x, max2(z3_x, z3_y) >= z3_y, Or(max2(z3_y, z3_x) == z3_x, max2(z3_y, z3_x) == z3_y))\n",
    "\n",
    "verification_oracle_instance = verification_oracle(z3_input_variable_list, z3_function_declaration, z3_constraint)\n",
    "next(verification_oracle_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354c6fb9-a138-4ce4-beb4-70e9829773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stderr\n",
    "\n",
    "import numpy as np\n",
    "from sympy import *\n",
    "\n",
    "from recursive_default_dict import RecursiveDefaultDict\n",
    "\n",
    "\n",
    "def calculate_entropy(\n",
    "    subset_of_input_set,\n",
    "    term_cover\n",
    "):\n",
    "    number_of_inputs_covered_by_terms_in_subset_of_input_set = [\n",
    "        len(term_cover_of_term & subset_of_input_set)\n",
    "        for term_cover_of_term in term_cover.values()\n",
    "    ]\n",
    "\n",
    "    probabilities_of_inputs_in_subset_of_input_set_labeled_by_terms = np.zeros((\n",
    "        len(subset_of_input_set), len(term_cover)\n",
    "    ))\n",
    "    for i, input_in_subset_of_input_set in enumerate(subset_of_input_set):\n",
    "        # Fill row (with add one smoothing)\n",
    "        for j, (term, term_cover_of_term) in enumerate(term_cover.items()):\n",
    "            if input_in_subset_of_input_set in term_cover_of_term:\n",
    "                probabilities_of_inputs_in_subset_of_input_set_labeled_by_terms[i, j] = number_of_inputs_covered_by_terms_in_subset_of_input_set[j] + 1\n",
    "            else:\n",
    "                probabilities_of_inputs_in_subset_of_input_set_labeled_by_terms[i, j] = 1\n",
    "        \n",
    "        # Normalize row (with add one smoothing)\n",
    "        probabilities_of_inputs_in_subset_of_input_set_labeled_by_terms[i, :] /= (np.sum(probabilities_of_inputs_in_subset_of_input_set_labeled_by_terms[i, :]) + len(term_cover))\n",
    "\n",
    "    # Calculate the (equally weighted) sum of all rows, and normalize\n",
    "    probabilities_of_any_input_in_subset_of_input_set_labeled_by_terms = np.sum(probabilities_of_inputs_in_subset_of_input_set_labeled_by_terms, axis=0)\n",
    "    probabilities_of_any_input_in_subset_of_input_set_labeled_by_terms /= np.sum(probabilities_of_any_input_in_subset_of_input_set_labeled_by_terms)\n",
    "\n",
    "    # Calculate entropy\n",
    "    entropy = -np.sum(probabilities_of_any_input_in_subset_of_input_set_labeled_by_terms * np.log2(probabilities_of_any_input_in_subset_of_input_set_labeled_by_terms))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calculate_information_gain(\n",
    "    predicate,\n",
    "    input_set,\n",
    "    term_cover,\n",
    "    predicate_cover\n",
    "):\n",
    "    predicate_cover_of_predicate = predicate_cover[predicate]\n",
    "    other_points = input_set - predicate_cover_of_predicate\n",
    "\n",
    "    return (len(predicate_cover_of_predicate) * calculate_entropy(predicate_cover_of_predicate, term_cover) + len(other_points) * calculate_entropy(other_points, term_cover)) / len(input_set)\n",
    "\n",
    "\n",
    "class EmptyPredicateSetError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def construct_decision_tree(\n",
    "    input_set,\n",
    "    term_cover,\n",
    "    predicate_set,\n",
    "    predicate_cover\n",
    "):\n",
    "    print('construct_decision_tree', input_set, term_cover, predicate_set, predicate_cover, file=stderr)\n",
    "    \n",
    "    terms_covering_all_inputs_list = [\n",
    "        term\n",
    "        for term, term_cover_of_term\n",
    "        in term_cover.items()\n",
    "        if input_set.issubset(term_cover_of_term)\n",
    "    ]\n",
    "\n",
    "    print('terms_covering_all_inputs_list', terms_covering_all_inputs_list, file=stderr)\n",
    "\n",
    "    if terms_covering_all_inputs_list:\n",
    "        return terms_covering_all_inputs_list.pop()\n",
    "    \n",
    "    if not predicate_set:\n",
    "        raise EmptyPredicateSetError\n",
    "    \n",
    "    predicate_list = []\n",
    "    information_gain_list = []\n",
    "\n",
    "    for predicate in predicate_set:\n",
    "        predicate_list.append(predicate)\n",
    "        information_gain_list.append(calculate_information_gain(predicate, input_set, term_cover, predicate_cover))\n",
    "    \n",
    "    argmax = np.nanargmax(information_gain_list)\n",
    "    predicate = predicate_list[argmax]\n",
    "\n",
    "    print('predicate_list:', predicate_list, file=stderr)\n",
    "    print('information_gain_list:', information_gain_list, file=stderr)\n",
    "\n",
    "    left_subtree_input_set = predicate_cover[predicate]\n",
    "    left_subtree_term_cover = {\n",
    "        term: left_subtree_input_set & term_cover_of_term\n",
    "        for term, term_cover_of_term\n",
    "        in term_cover.items()\n",
    "    }\n",
    "    left_subtree_predicate_set = predicate_set - {predicate}\n",
    "    left_subtree_predicate_cover = {\n",
    "        left_subtree_predicate: left_subtree_input_set & predicate_cover[left_subtree_predicate]\n",
    "        for left_subtree_predicate in left_subtree_predicate_set\n",
    "    }\n",
    "    left_subtree = construct_decision_tree(\n",
    "        left_subtree_input_set,\n",
    "        left_subtree_term_cover,\n",
    "        left_subtree_predicate_set,\n",
    "        left_subtree_predicate_cover\n",
    "    )\n",
    "\n",
    "    right_subtree_input_set = input_set - predicate_cover[predicate]\n",
    "    right_subtree_term_cover = {\n",
    "        term: right_subtree_input_set & term_cover_of_term\n",
    "        for term, term_cover_of_term\n",
    "        in term_cover.items()\n",
    "    }\n",
    "    right_subtree_predicate_set = predicate_set - {predicate}\n",
    "    right_subtree_predicate_cover = {\n",
    "        right_subtree_predicate: right_subtree_input_set & predicate_cover[right_subtree_predicate]\n",
    "        for right_subtree_predicate in right_subtree_predicate_set\n",
    "    }\n",
    "    right_subtree = construct_decision_tree(\n",
    "        right_subtree_input_set,\n",
    "        right_subtree_term_cover,\n",
    "        right_subtree_predicate_set,\n",
    "        right_subtree_predicate_cover\n",
    "    )\n",
    "\n",
    "    return (predicate, left_subtree, right_subtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386398d5-2627-4217-9c89-7bf1bd8bf3da",
   "metadata": {},
   "source": [
    "```\n",
    "def divide_and_conquer_enumerative_approach(\n",
    "    non_terminals,\n",
    "    terminals,\n",
    "    production_rules,\n",
    "    term_non_terminal,\n",
    "    predicate_non_terminal,\n",
    "    inputs_and_outputs\n",
    "):\n",
    "    term_iterator = bottom_up_tree_search(non_terminals, terminals, production_rules, term_non_terminal)\n",
    "    predicate_iterator = bottom_up_tree_search(non_terminals, terminals, production_rules, predicate_non_terminal)\n",
    "\n",
    "    input_set = { input_ for input_, output in inputs_and_outputs }\n",
    "\n",
    "    term_cover = dict()\n",
    "\n",
    "    predicate_set = set()\n",
    "    predicate_cover = dict()\n",
    "\n",
    "    def generate_and_handle_new_term():\n",
    "        nonlocal term_iterator, inputs_and_outputs, term_cover\n",
    "\n",
    "        # Generate new term\n",
    "        term = next(term_iterator)\n",
    "\n",
    "        # Update term_cover\n",
    "        term_cover_of_term = set()\n",
    "        for (input_, output) in inputs_and_outputs:\n",
    "            if term.subs(input_) == output:\n",
    "                term_cover_of_term.add(input_)\n",
    "        \n",
    "        term_cover[term] = term_cover_of_term\n",
    "    \n",
    "    def generate_and_handle_new_predicate():\n",
    "        nonlocal predicate_iterator, inputs_and_outputs, predicate_set, predicate_cover\n",
    "\n",
    "        # Generate new predicate\n",
    "        predicate = next(predicate_iterator)\n",
    "\n",
    "        # Add to predicate_set\n",
    "        predicate_set.add(predicate)\n",
    "\n",
    "        # Update predicate_cover\n",
    "        predicate_cover_of_predicate = set()\n",
    "        for (input_, output) in inputs_and_outputs:\n",
    "            if predicate.subs(input_):\n",
    "                predicate_cover_of_predicate.add(input_)\n",
    "        \n",
    "        predicate_cover[predicate] = predicate_cover_of_predicate\n",
    "\n",
    "\n",
    "    while set().union(*term_cover.values()) != input_set:\n",
    "        generate_and_handle_new_term()\n",
    "    \n",
    "    print('term_cover:', term_cover, file=stderr)\n",
    "    \n",
    "    while True:\n",
    "        generate_and_handle_new_term()\n",
    "        generate_and_handle_new_predicate()\n",
    "\n",
    "        print('term_cover:', term_cover, file=stderr)\n",
    "        print('predicate_cover:', predicate_cover, file=stderr)\n",
    "\n",
    "        # Construct a Decision Tree and yield\n",
    "        try:\n",
    "            yield construct_decision_tree(input_set, term_cover, predicate_set, predicate_cover)\n",
    "        except Exception as e:\n",
    "            # Write the class of the exception and the message of the exception to stderr\n",
    "            print(type(e).__name__, str(e), file=stderr)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78556df-6a80-42cd-8951-e610eeb752df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.core.add import Add\n",
    "from sympy.core.function import Function\n",
    "from sympy.core.mul import Mul\n",
    "from sympy.core.numbers import Integer\n",
    "from sympy.core.relational import Equality, GreaterThan, LessThan\n",
    "from sympy.core.symbol import Symbol\n",
    "from sympy.logic.boolalg import And, Or, Not\n",
    "from sympy.functions.elementary.piecewise import ExprCondPair, Piecewise\n",
    "\n",
    "\n",
    "S = Symbol('S')\n",
    "B = Symbol('B')\n",
    "x = Symbol('x')\n",
    "y = Symbol('y')\n",
    "\n",
    "non_terminals = { S, B }\n",
    "terminals = { x, y }\n",
    "# non_terminals to a set of tuples containing the production_rule in reverse_polish_notation\n",
    "production_rules = {\n",
    "  S: {\n",
    "    # x\n",
    "    (x,),\n",
    "    # y\n",
    "    (y,),\n",
    "    # 0\n",
    "    (Integer(0),),\n",
    "    # 1\n",
    "    (Integer(1),),\n",
    "    # + S S\n",
    "    (S, S, (Add, 2)),\n",
    "    # - S S\n",
    "    (S, Integer(-1), S, (Mul, 2), (Add, 2)),\n",
    "    # ite B S S\n",
    "    (S, B, (ExprCondPair, 2), S, True, (ExprCondPair, 2), (Piecewise, 2)),\n",
    "  },\n",
    "  B: {\n",
    "    # and B B\n",
    "    (B, B, (And, 2)),\n",
    "    # or B B\n",
    "    (B, B, (Or, 2)),\n",
    "    # not B\n",
    "    (B, (Not, 1)),\n",
    "    # <= S S\n",
    "    (S, S, (LessThan, 2)),\n",
    "    # = S S\n",
    "    (S, S, (Equality, 2)),\n",
    "    # >= S S\n",
    "    (S, S, (GreaterThan, 2)),\n",
    "  }\n",
    "}\n",
    "start_symbol = S\n",
    "\n",
    "function_declaration = max2 = Function('max2')\n",
    "constraint = And(GreaterThan(max2(x, y), x), GreaterThan(max2(x, y), y), Or(Equality(max2(y, x), x), Equality(max2(y, x), y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37179af2-a599-4fad-b8a4-b1e5859c76cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bottom_up_tree_search import *\n",
    "\n",
    "term_iterator = enumeration(non_terminals, terminals, production_rules, start_symbol)\n",
    "predicate_iterator = enumeration(non_terminals, terminals, production_rules, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "144dfb77-6bcf-4449-916f-9280aef6dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_cover = dict()\n",
    "predicate_set = set()\n",
    "predicate_cover = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50bb9ed-d514-4559-ab96-8a11f3e91e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated from verification oracle\n",
    "counterexample_input_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8fe0271-38f9-48f2-81ae-0ae178e961a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_candidate_program_on_input(\n",
    "    function_declaration,\n",
    "    constraint,\n",
    "    candidate_program,\n",
    "    counterexample_input\n",
    "):\n",
    "    return replace_function_declaration_in_constraint_with_candidate_program(\n",
    "        counterexample_input,\n",
    "        function_declaration,\n",
    "        constraint,\n",
    "        candidate_program\n",
    "    ).subs(counterexample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7494323a-115d-49eb-a255-79b1cb955ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_handle_new_term():\n",
    "    global function_declaration, constraint, term_iterator, term_cover, counterexample_input_set\n",
    "\n",
    "    # Generate new term\n",
    "    term = next(term_iterator)\n",
    "\n",
    "    # Update term_cover\n",
    "    term_cover_of_term = set()\n",
    "    for counterexample_input in counterexample_input_set:\n",
    "        if evaluate_candidate_program_on_input(\n",
    "            function_declaration,\n",
    "            constraint,\n",
    "            term,\n",
    "            counterexample_input\n",
    "        ):\n",
    "            term_cover_of_term.add(counterexample_input)\n",
    "\n",
    "    term_cover[term] = term_cover_of_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da1f79b-a037-47bd-b6b1-1ecf722437d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_handle_new_predicate():\n",
    "    global function_declaration, constraint, predicate_iterator, predicate_set, predicate_cover, counterexample_input_set\n",
    "\n",
    "    # Generate new predicate\n",
    "    predicate = next(predicate_iterator)\n",
    "\n",
    "    # Add to predicate_set\n",
    "    predicate_set.add(predicate)\n",
    "\n",
    "    # Update predicate_cover\n",
    "    predicate_cover_of_predicate = set()\n",
    "    for counterexample_input in counterexample_input_set:\n",
    "        if predicate.subs(counterexample_input):\n",
    "            predicate_cover_of_predicate.add(counterexample_input)\n",
    "    \n",
    "    predicate_cover[predicate] = predicate_cover_of_predicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df8239-6bc3-49c8-aef2-99ce7406d75b",
   "metadata": {},
   "source": [
    "```python\n",
    "    while set().union(*term_cover.values()) != input_set:\n",
    "        generate_and_handle_new_term()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df6fc51e-5449-4513-8d20-e850ad2eddb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set().union(*term_cover.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d0a4d7a-57fc-49dc-b4b8-c4d3f6f25a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counterexample_input_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a7dc22-8ea2-45c8-bc8c-dc13c98417c0",
   "metadata": {},
   "source": [
    "```python\n",
    "    while True:\n",
    "        generate_and_handle_new_term()\n",
    "        generate_and_handle_new_predicate()\n",
    "\n",
    "        print('term_cover:', term_cover, file=stderr)\n",
    "        print('predicate_cover:', predicate_cover, file=stderr)\n",
    "\n",
    "        # Construct a Decision Tree and yield\n",
    "        try:\n",
    "            yield construct_decision_tree(input_set, term_cover, predicate_set, predicate_cover)\n",
    "        except Exception as e:\n",
    "            # Write the class of the exception and the message of the exception to stderr\n",
    "            print(type(e).__name__, str(e), file=stderr)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbe8b62d-9401-4fdf-ab91-4b6724cc2380",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_handle_new_term()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbcab858-9e59-4e7a-8ef5-c9ebedb9f7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: set()}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f560d8-cd1f-431a-932f-1f58a2bc197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_handle_new_predicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ebdc74-6507-4074-9ff8-52a35bd14894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{True: set()}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicate_cover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3a72a-9bb4-42ad-bde2-c0098938e96e",
   "metadata": {},
   "source": [
    "```python\n",
    "def construct_decision_tree(\n",
    "    counterexample_input_set,\n",
    "    term_cover,\n",
    "    predicate_set,\n",
    "    predicate_cover\n",
    "):\n",
    "    print('construct_decision_tree', counterexample_input_set, term_cover, predicate_set, predicate_cover, file=stderr)\n",
    "    \n",
    "    terms_covering_all_inputs_list = [\n",
    "        term\n",
    "        for term, term_cover_of_term\n",
    "        in term_cover.items()\n",
    "        if counterexample_input_set.issubset(term_cover_of_term)\n",
    "    ]\n",
    "\n",
    "    print('terms_covering_all_inputs_list', terms_covering_all_inputs_list, file=stderr)\n",
    "\n",
    "    if terms_covering_all_inputs_list:\n",
    "        return terms_covering_all_inputs_list.pop()\n",
    "    \n",
    "    if not predicate_set:\n",
    "        raise EmptyPredicateSetError\n",
    "    \n",
    "    predicate_list = []\n",
    "    information_gain_list = []\n",
    "\n",
    "    for predicate in predicate_set:\n",
    "        predicate_list.append(predicate)\n",
    "        information_gain_list.append(calculate_information_gain(predicate, counterexample_input_set, term_cover, predicate_cover))\n",
    "    \n",
    "    argmax = np.nanargmax(information_gain_list)\n",
    "    predicate = predicate_list[argmax]\n",
    "\n",
    "    print('predicate_list:', predicate_list, file=stderr)\n",
    "    print('information_gain_list:', information_gain_list, file=stderr)\n",
    "\n",
    "    left_subtree_input_set = predicate_cover[predicate]\n",
    "    left_subtree_term_cover = {\n",
    "        term: left_subtree_input_set & term_cover_of_term\n",
    "        for term, term_cover_of_term\n",
    "        in term_cover.items()\n",
    "    }\n",
    "    left_subtree_predicate_set = predicate_set - {predicate}\n",
    "    left_subtree_predicate_cover = {\n",
    "        left_subtree_predicate: left_subtree_input_set & predicate_cover[left_subtree_predicate]\n",
    "        for left_subtree_predicate in left_subtree_predicate_set\n",
    "    }\n",
    "    left_subtree = construct_decision_tree(\n",
    "        left_subtree_input_set,\n",
    "        left_subtree_term_cover,\n",
    "        left_subtree_predicate_set,\n",
    "        left_subtree_predicate_cover\n",
    "    )\n",
    "\n",
    "    right_subtree_input_set = counterexample_input_set - predicate_cover[predicate]\n",
    "    right_subtree_term_cover = {\n",
    "        term: right_subtree_input_set & term_cover_of_term\n",
    "        for term, term_cover_of_term\n",
    "        in term_cover.items()\n",
    "    }\n",
    "    right_subtree_predicate_set = predicate_set - {predicate}\n",
    "    right_subtree_predicate_cover = {\n",
    "        right_subtree_predicate: right_subtree_input_set & predicate_cover[right_subtree_predicate]\n",
    "        for right_subtree_predicate in right_subtree_predicate_set\n",
    "    }\n",
    "    right_subtree = construct_decision_tree(\n",
    "        right_subtree_input_set,\n",
    "        right_subtree_term_cover,\n",
    "        right_subtree_predicate_set,\n",
    "        right_subtree_predicate_cover\n",
    "    )\n",
    "\n",
    "    return (predicate, left_subtree, right_subtree)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b0efe93-4b8c-47f8-9b71-c84d21457a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_covering_all_inputs_list = [\n",
    "    term\n",
    "    for term, term_cover_of_term\n",
    "    in term_cover.items()\n",
    "    if counterexample_input_set.issubset(term_cover_of_term)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ff14858-c4e9-4b15-99fe-b44e029cd962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_covering_all_inputs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52e685-dcaf-412c-9b39-1195634a732f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
